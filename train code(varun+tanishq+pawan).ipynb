{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "641d2747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All sequences shape: (224517, 30, 126)\n",
      "All labels shape: (224517,)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Function to load landmarks from a JSON file.\n",
    "def load_landmarks(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Extract hand keypoints.\n",
    "    hand_left_keypoints = []\n",
    "    hand_right_keypoints = []\n",
    "    \n",
    "    for person in data['people']:\n",
    "        left_hand = person['hand_left_keypoints_2d']\n",
    "        right_hand = person['hand_right_keypoints_2d']\n",
    "        \n",
    "        if left_hand:\n",
    "            hand_left_keypoints.append(left_hand)\n",
    "        if right_hand:\n",
    "            hand_right_keypoints.append(right_hand)\n",
    "    \n",
    "    return np.array(hand_left_keypoints), np.array(hand_right_keypoints)\n",
    "\n",
    "# Function to create sequences from the landmark data.\n",
    "def create_sequences(data, sequence_length=30):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        sequences.append(data[i:i + sequence_length])\n",
    "    return np.array(sequences)\n",
    "\n",
    "# Directory containing the JSON files.\n",
    "json_dir = r\"D:\\dataset\\openpose_output_val\\output\"  # Replace with the actual path to your directory\n",
    "json_files = glob(os.path.join(json_dir, '*.json'))\n",
    "\n",
    "# Initialize lists to hold all sequences and labels.\n",
    "all_sequences = []\n",
    "all_labels = []\n",
    "\n",
    "# Process each JSON file.\n",
    "for json_file in json_files:\n",
    "    left_hand_data, right_hand_data = load_landmarks(json_file)\n",
    "    \n",
    "    # Create sequences for both left and right hand data.\n",
    "    sequence_length = 30\n",
    "    left_hand_sequences = create_sequences(left_hand_data, sequence_length)\n",
    "    right_hand_sequences = create_sequences(right_hand_data, sequence_length)\n",
    "\n",
    "    # Combine left and right hand sequences if both are available.\n",
    "    if left_hand_sequences.shape[0] > 0 and right_hand_sequences.shape[0] > 0:\n",
    "        combined_sequences = np.concatenate([left_hand_sequences, right_hand_sequences], axis=-1)\n",
    "    else:\n",
    "        combined_sequences = left_hand_sequences if left_hand_sequences.shape[0] > 0 else right_hand_sequences\n",
    "\n",
    "    # Flatten the landmarks.\n",
    "    if combined_sequences.shape[0] > 0:\n",
    "        num_features = combined_sequences.shape[-2] * combined_sequences.shape[-1]\n",
    "        flattened_sequences = combined_sequences.reshape(combined_sequences.shape[0], combined_sequences.shape[1], num_features)\n",
    "        \n",
    "        # Append to the list of all sequences.\n",
    "        all_sequences.append(flattened_sequences)\n",
    "        \n",
    "        # Generate labels (assuming all sequences from the same file belong to the same class in this example).\n",
    "        labels = np.array([1] * len(flattened_sequences))  # Change '1' to the actual label for the sign.\n",
    "        all_labels.append(labels)\n",
    "\n",
    "# Combine all sequences and labels.\n",
    "all_sequences = np.concatenate(all_sequences, axis=0)\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "# Save the sequences and labels.\n",
    "np.save(r\"D:\\dataset\\new\", all_sequences)\n",
    "np.save(r\"D:\\dataset\\new2\", all_labels)\n",
    "\n",
    "print(f\"All sequences shape: {all_sequences.shape}\")\n",
    "print(f\"All labels shape: {all_labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77b476f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 367ms/step - accuracy: 0.6979 - loss: 0.6323 - val_accuracy: 1.0000 - val_loss: 0.4578\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9674 - loss: 0.4774 - val_accuracy: 1.0000 - val_loss: 0.3133\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.3520 - val_accuracy: 1.0000 - val_loss: 0.2002\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.2196 - val_accuracy: 1.0000 - val_loss: 0.1155\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.1461 - val_accuracy: 1.0000 - val_loss: 0.0626\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0855 - val_accuracy: 1.0000 - val_loss: 0.0328\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0475 - val_accuracy: 1.0000 - val_loss: 0.0172\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0224 - val_accuracy: 1.0000 - val_loss: 0.0093\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0155 - val_accuracy: 1.0000 - val_loss: 0.0053\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Load the sequences and labels.\n",
    "sequences = np.load(r\"D:\\dataset\\new.npy\")\n",
    "labels = np.load(r\"D:\\dataset\\new2.npy\")\n",
    "# Split the data into training and testing sets.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the LSTM model.\n",
    "sequence_length = 30\n",
    "num_features = sequences.shape[2]\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(sequence_length, num_features)),\n",
    "    Dropout(0.5),\n",
    "    LSTM(64),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='tanh'),\n",
    "    Dense(1, activation='sigmoid')  # Change to the number of classes if more than 1.\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model.\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Save the model with a valid extension.\n",
    "model.save(r\"D:\\dataset\\new.keras\")\n",
    "\n",
    "print(\"Model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0fecd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
